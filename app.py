# KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import re
from collections import Counter
from itertools import combinations
import os

# ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬
import matplotlib.pyplot as plt
import seaborn as sns
import altair as alt
import plotly.express as px
import plotly.graph_objects as go

# í…ìŠ¤íŠ¸ ì²˜ë¦¬
from konlpy.tag import Okt
from wordcloud import WordCloud

# ë„¤íŠ¸ì›Œí¬ ë¶„ì„
import networkx as nx

# í•œê¸€ í°íŠ¸ ì„¤ì •  - Pretendard í°íŠ¸ ì‚¬ìš©
import matplotlib.font_manager as fm

# Pretendard í°íŠ¸ ê²½ë¡œ ì„¤ì •
font_path = 'font/Pretendard-Regular.ttf'
if os.path.exists(font_path):
    fm.fontManager.addfont(font_path)
    plt.rcParams['font.family'] = 'Pretendard'
plt.rcParams['axes.unicode_minus'] = False

# í˜ì´ì§€ ì„¤ì • (ê°•ì˜ë¡ 11.ipynb)
st.set_page_config(
    page_title='KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ ë¶„ì„',
    page_icon='ğŸµ',
    layout='wide',
    initial_sidebar_state='expanded',
    menu_items={
        'Get help': 'https://docs.streamlit.io',
        'Report a bug': 'https://streamlit.io',
        'About': '### KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ \n - C221088 ì•Œë ‰ì‚°ë”'
    }
)

# ë¶ˆìš©ì–´ ì •ì˜
# ë¶ˆìš©ì–´ ì‚¬ì „ ë§Œë“¤ê¸°
stop_str = 'ì˜ˆì • ì— ê°€ ì´ì€ ì„ ë¥¼ ì˜ ë„ ë˜í•œ ë” ë¥¼ ìœ„í•´ ì—ê²Œ ì—ê²Œì„œ ì—ê²Œë¡œ ë¶€í„° ì–´ ìš°ì„  ê°„ ì´í›„ í•˜ëŠ” ì…ë‹ˆë‹¤ í•  í•©ë‹ˆë‹¤'
# ë¶ˆìš©ì–´ ë¬¸ìì—´ì„ ' 'ë¡œ ë¶„ë¦¬í•œ í›„ setìœ¼ë¡œ ë³€í™˜
stop_words = set(stop_str.split(' '))

# í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜
def cleanString(text):
    """í…ìŠ¤íŠ¸ ì •ì œ í•¨ìˆ˜"""
    # HTML íƒœê·¸ ì œê±° (ê°•ì˜ë¡ 13.ipynb)
    pattern = r'(<[^>]*>)'
    text = re.sub(pattern=pattern, repl='', string=text)
    
    # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    pattern = r'[^\w\s\n]'
    text = re.sub(pattern=pattern, repl='', string=text)
    
    return text

# ìºì‹± í•¨ìˆ˜ ì •ì˜
@st.cache_data
def load_data():
    """ë°ì´í„° ë¡œë“œ í•¨ìˆ˜"""
    df = pd.read_csv('data/naver_news.csv')
    df['pubDate'] = pd.to_datetime(df['pubDate'])
    df['date'] = pd.to_datetime(df['date'])
    return df

# ì‚¬ì´ë“œë°” êµ¬ì„±
# ì‚¬ì´ë“œë°” ì„¤ì •
st.sidebar.title('ğŸµ KíŒ ë°ëª¬ í—Œí„°ìŠ¤')
st.sidebar.divider()  # êµ¬ë¶„ì„ 

# í•™ë²ˆ, ì´ë¦„ í‘œì‹œ
st.sidebar.info('**C221088 ìµœìœ ë¹ˆ**')

st.sidebar.write('### ğŸ“Š ë¶„ì„ ì˜µì…˜')

# ìœ„ì ¯ 1: ì²´í¬ë°•ìŠ¤
show_raw_data = st.sidebar.checkbox('ì›ë³¸ ë°ì´í„° ë³´ê¸°')

# ìœ„ì ¯ 2: ìŠ¬ë¼ì´ë”
top_n_words = st.sidebar.slider('ì›Œë“œí´ë¼ìš°ë“œ ë‹¨ì–´ ìˆ˜', 10, 100, 50)

# ìœ„ì ¯ 3: ì…€ë ‰íŠ¸ë°•ìŠ¤
network_min_weight = st.sidebar.selectbox(
    'ë„¤íŠ¸ì›Œí¬ ìµœì†Œ ì—°ê²° ê°•ë„',
    [3, 5, 10, 15, 20]
)

# ìœ„ì ¯ 4: ë¼ë””ì˜¤ ë²„íŠ¼
chart_theme = st.sidebar.radio(
    'ì°¨íŠ¸ ìƒ‰ìƒ í…Œë§ˆ',
    ['ê¸°ë³¸', 'ë‹¤í¬', 'ì»¬ëŸ¬í’€']
)

# ìœ„ì ¯ 5: ë©€í‹°ì…€ë ‰íŠ¸
analysis_options = st.sidebar.multiselect(
    'ë¶„ì„ í•­ëª© ì„ íƒ',
    ['ì‹œê³„ì—´ ë¶„ì„', 'í‚¤ì›Œë“œ ì¶”ì´ ë¶„ì„', 'í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„', 'ì›Œë“œí´ë¼ìš°ë“œ', 'ë„¤íŠ¸ì›Œí¬ ë¶„ì„'],
    default=['ì‹œê³„ì—´ ë¶„ì„', 'í‚¤ì›Œë“œ ì¶”ì´ ë¶„ì„', 'í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„', 'ì›Œë“œí´ë¼ìš°ë“œ', 'ë„¤íŠ¸ì›Œí¬ ë¶„ì„']
)

st.sidebar.divider()  # êµ¬ë¶„ì„ 
st.sidebar.caption('Â© 2025 ë°ì´í„°ì‹œê°í™” 3ì°¨ ì‹œí—˜')

# ë©”ì¸ í˜ì´ì§€

# íƒ€ì´í‹€
st.title('ğŸµ KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ')
st.markdown('**C221088 ìµœìœ ë¹ˆ** | ë°ì´í„°ì‹œê°í™” 3ì°¨ ì‹œí—˜')
st.divider()  # êµ¬ë¶„ì„ 

# 1. ì‘í’ˆ ê¸°ë³¸ ì •ë³´ ì„¹ì…˜
st.header('ğŸ“º ì‘í’ˆ ê¸°ë³¸ ì •ë³´')

# ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([1, 2])

with col1:
    # ì´ë¯¸ì§€ ì¶œë ¥
    if os.path.exists('data/poster.jpg'):
        st.image('data/poster.jpg', caption='KíŒ ë°ëª¬ í—Œí„°ìŠ¤ í¬ìŠ¤í„°', use_container_width=True)
    elif os.path.exists('data/poster.png'):
        st.image('data/poster.png', caption='KíŒ ë°ëª¬ í—Œí„°ìŠ¤ í¬ìŠ¤í„°', use_container_width=True)
    else:
        st.image('https://via.placeholder.com/300x400?text=Poster', 
                 caption='KíŒ ë°ëª¬ í—Œí„°ìŠ¤', use_container_width=True)

with col2:
    # ì‘í’ˆ ì •ë³´
    st.subheader('K-Pop Demon Hunters')
    
    # Pandas ë°ì´í„°í”„ë ˆì„ ì¶œë ¥
    info_df = pd.DataFrame({
        'í•­ëª©': ['ê°œë´‰ì¼', 'ì±„ë„', 'ê°ë…', 'ì¥ë¥´'],
        'ë‚´ìš©': ['2025ë…„ 6ì›” 20ì¼', 'ë„·í”Œë¦­ìŠ¤', 'ë§¤ê¸° ê°•, í¬ë¦¬ìŠ¤ ì•„í í•œìŠ¤', 'íŒíƒ€ì§€, ì•¡ì…˜, ìŒì•…']
    })
    st.dataframe(info_df, use_container_width=True, hide_index=True)
    
    st.write('#### ğŸ“– ì¤„ê±°ë¦¬')
    st.write('''
   ì„¸ê³„ì ì¸ íŒ¬ë¤ì„ ê±°ëŠë¦° ìµœì •ìƒ K-Pop ê±¸ê·¸ë£¹. í™”ë ¤í•œ ì¡°ëª… ì•„ë˜ì„œ ì™„ë²½í•œ í¼í¬ë¨¼ìŠ¤ë¥¼ ë³´ì—¬ì£¼ëŠ” ê·¸ë“¤ì´ì§€ë§Œ, ë¬´ëŒ€ ë’¤ì—ëŠ” ì•„ë¬´ë„ ëª¨ë¥´ëŠ” ë¹„ë°€ì´ ìˆìŠµë‹ˆë‹¤. ë°”ë¡œ ì‚¬ì•…í•œ **ì•…ê·€(Demon)ë“¤ì„ í‡´ì¹˜í•˜ëŠ” ë¹„ë°€ ìš”ì› 'ë°ëª¬ í—Œí„°'**ë¼ëŠ” ì‚¬ì‹¤ì…ë‹ˆë‹¤.
   ë©¤ë²„ë“¤ì€ ì»´ë°± ì¤€ë¹„ì™€ ì›”ë“œ íˆ¬ì–´ë¼ëŠ” ì‚´ì¸ì ì¸ ìŠ¤ì¼€ì¤„ ì†ì—ì„œë„, í‹ˆí‹ˆì´ ì¶œëª°í•˜ëŠ” ì•…ê·€ë“¤ì„ ì²˜ì¹˜í•˜ë©° ì„¸ìƒì„ êµ¬í•´ì•¼ í•©ë‹ˆë‹¤. í™”ë ¤í•œ íŒ¨ì…˜ê³¼ ë§›ìˆëŠ” ìŒì‹, ê·¸ë¦¬ê³  ë©¤ë²„ë“¤ ê°„ì˜ ëˆëˆí•œ ìš°ì •ì„ ë°”íƒ•ìœ¼ë¡œ ì•…ì˜ ì„¸ë ¥ì— ë§ì„œëŠ” ì´ì•¼ê¸°ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.
    ''')

st.divider()

# 2. ë“±ì¥ì¸ë¬¼ ì„¹ì…˜
st.header('ğŸ­ ì£¼ìš”ì¸ë¬¼')

# ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
char_cols = st.columns(5)

# ìºë¦­í„° ì •ë³´ ë¦¬ìŠ¤íŠ¸
characters = [
    {'name': 'ë£¨ë¯¸', 'role': 'ë¦¬ë”', 'image': 'data/rumi.png'},
    {'name': 'ë¯¸ë¼', 'role': 'ë˜í¼', 'image': 'data/mira.png'},
    {'name': 'ì¡°ì´', 'role': 'ë˜í¼', 'image': 'data/joy.png'}
]

for i, char in enumerate(characters):
    with char_cols[i]:
        # ì´ë¯¸ì§€ ì¶œë ¥
        if os.path.exists(char['image']):
            st.image(char['image'], use_container_width=True)
        else:
            st.image(f'https://via.placeholder.com/150x200?text={char["name"]}', 
                    use_container_width=True)
        st.write(f"**{char['name']}**")
        st.caption(char['role'])

st.divider()  # êµ¬ë¶„ì„ 

# 3. ê´€ë ¨ ì˜ìƒ ë° ìŒì•…
st.header('ğŸ¬ ê´€ë ¨ ë¯¸ë””ì–´')

media_col1, media_col2 = st.columns(2)

with media_col1:
    st.write('#### ğŸ“¹ ê´€ë ¨ ì˜ìƒ')
    # í…ìŠ¤íŠ¸ ì…ë ¥
    youtube_url = st.text_input('https://www.youtube.com/watch?v=7vCK0VBuQLs&list=RD7vCK0VBuQLs&start_radio=1', 
                                placeholder='https://www.youtube.com/watch?v=...')
    if youtube_url:
        # ë™ì˜ìƒ ì¶œë ¥
        st.video(youtube_url)

st.divider()  # êµ¬ë¶„ì„ 

# ë°ì´í„° ë¡œë“œ
st.header('ğŸ“Š ë°ì´í„° ë¶„ì„')

# ë°ì´í„° ë¡œë“œ ì‹œë„
try:
    df = load_data()
    data_loaded = True
    st.success(f'ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(df)}ê°œì˜ ê¸°ì‚¬')
except FileNotFoundError:
    st.warning('âš ï¸ ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. data.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.')
    data_loaded = False
    
    # ìƒ˜í”Œ ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©)
    st.info('í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.')
    
    np.random.seed(42)
    dates = pd.date_range(start='2025-06-15', end='2025-09-20', freq='D')
    
    # ìƒ˜í”Œ ë°ì´í„°
    sample_data = []
    keywords = ['ë…¸ë˜', 'ì¼€ì´íŒ', 'í•œêµ­', 'ë„·í”Œë¦­ìŠ¤', 'ì¸ê¸°', 'ì‘ì›', 'ìµœê³ ', 'ë¬¸í™”', 'ì£¼ë§', 'ì•„ì´ëŒ', 'ì¼€ë°í—Œ', 'ì¼€ë°í—Œ íš¨ê³¼']
    
    for date in dates:
        n_articles = np.random.randint(50, 300)
        for _ in range(n_articles // 10):
            title = f"ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ {np.random.choice(keywords)} í™”ì œ"
            desc = f"{np.random.choice(keywords)} {np.random.choice(keywords)} ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ {np.random.choice(keywords)}"
            sample_data.append({
                'pubDate': date,
                'title': title,
                'description': desc,
                'date': date
            })
    
    df = pd.DataFrame(sample_data)
    df['pubDate'] = pd.to_datetime(df['pubDate'])
    df['date'] = pd.to_datetime(df['date'])
    data_loaded = True

# ì›ë³¸ ë°ì´í„° í‘œì‹œ
if data_loaded and show_raw_data:
    st.subheader('ğŸ“‹ ì›ë³¸ ë°ì´í„°')
    st.dataframe(df.head(20))

# ì§€í‘œ í‘œì‹œ
if data_loaded:
    st.subheader('ğŸ“ˆ ì£¼ìš” ì§€í‘œ')
    
    # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
    col1, col2, col3 = st.columns(3)
    
    # ì§€í‘œ
    col1.metric("ì´ ê¸°ì‚¬ ìˆ˜", f"{len(df):,}ê°œ")
    col2.metric("ë¶„ì„ ê¸°ê°„", f"{(df['date'].max() - df['date'].min()).days}ì¼")
    col3.metric("ì¼í‰ê·  ê¸°ì‚¬", f"{len(df) / max((df['date'].max() - df['date'].min()).days, 1):.1f}ê°œ")
    
    st.divider()

# AI
# ì‹œê³„ì—´ ë¶„ì„ (Plotly)
if data_loaded and 'ì‹œê³„ì—´ ë¶„ì„' in analysis_options:
    st.header('ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„: ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ ì¶”ì´')
    st.write('> ì‹œê°„ì— ë”°ë¥¸ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ ë³€í™”ë¥¼ í†µí•´ **ê´€ì‹¬ë„ ì¶”ì´**ì™€ **ì£¼ìš” ì´ë²¤íŠ¸**ë¥¼ íŒŒì•…')
    
    # ì¼ë³„ ê¸°ì‚¬ ìˆ˜ ì§‘ê³„
    daily_counts = df.groupby('date').size().reset_index(name='count')
    
    # ì£¼ì°¨ ì •ë³´ ì¶”ê°€
    daily_counts['week'] = daily_counts['date'].dt.isocalendar().week
    daily_counts['month'] = daily_counts['date'].dt.month
    
    # Plotly ê·¸ë˜í”„
    fig = go.Figure()
    
    # ê°œë´‰ í›„ (6ì›”_ì˜í™” ê°œë´‰ë‹¬)
    mask1 = daily_counts['month'] == 6
    fig.add_trace(go.Scatter(
        x=daily_counts[mask1]['date'],
        y=daily_counts[mask1]['count'],
        mode='lines+markers',
        name='ê°œë´‰ í›„',
        line=dict(color='orange'),
        marker=dict(size=6)
    ))
    
    # í•œë‹¬ í›„ (7ì›”)
    mask2 = daily_counts['month'] == 7
    fig.add_trace(go.Scatter(
        x=daily_counts[mask2]['date'],
        y=daily_counts[mask2]['count'],
        mode='lines+markers',
        name='í•œë‹¬ í›„',
        line=dict(color='green'),
        marker=dict(size=6)
    ))
    
    # ë‘ë‹¬ ì´ìƒ (8~9ì›”)
    mask3 = daily_counts['month'] >= 8
    fig.add_trace(go.Scatter(
        x=daily_counts[mask3]['date'],
        y=daily_counts[mask3]['count'],
        mode='lines+markers',
        name='ë‘ë‹¬ ì´ìƒ',
        line=dict(color='coral'),
        marker=dict(size=6)
    ))
    
    fig.update_layout(
        title='ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜ ì¶”ì´',
        xaxis_title='ë‚ ì§œ',
        yaxis_title='ë‰´ìŠ¤ ìˆ˜',
        hovermode='x unified',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
    )
    
    # Plotly ì°¨íŠ¸ ì¶œë ¥
    st.plotly_chart(fig, use_container_width=True)
    
    # í•´ì„
    with st.expander('ğŸ“ ì‹œê³„ì—´ ë¶„ì„ í•´ì„'):
        st.write('''
        **ë¶„ì„ ê²°ê³¼:**
        - **ê°œë´‰ë‹¬(6ì›”)**: ì‘í’ˆ ê°œë´‰ê³¼ í•¨ê»˜ ê¸‰ê²©í•œ ê´€ì‹¬ ìƒìŠ¹
        - **í•œë‹¬ í›„(7ì›”)**: OST ë¹Œë³´ë“œ ì°¨íŠ¸ ì§„ì…ìœ¼ë¡œ ì•ˆì •ì  ê´€ì‹¬ ìœ ì§€
        - **ë‘ë‹¬ ì´ìƒ(8~9ì›”)**: ê¸€ë¡œë²Œ ì‹œì²­ ê¸°ë¡ ë‹¬ì„±ìœ¼ë¡œ ì¬í™•ì‚°
        ''')
    
    st.divider()

# í‚¤ì›Œë“œ ì¶”ì´ ë¶„ì„ (Altair)
if data_loaded and 'í‚¤ì›Œë“œ ì¶”ì´ ë¶„ì„' in analysis_options:
    st.header('ğŸ“Š ì£¼ìš” í‚¤ì›Œë“œ ì£¼ì°¨ë³„ ì–¸ê¸‰ ì¶”ì´')
    st.write('> ì‹œê°„ì— ë”°ë¥¸ **ì£¼ìš” í‚¤ì›Œë“œì˜ ì–¸ê¸‰ ë¹ˆë„ ë³€í™”**ë¥¼ ë¶„ì„')
    
    # í˜•íƒœì†Œ ë¶„ì„ê¸°
    okt = Okt()
    
    # ì£¼ì°¨ë³„ í‚¤ì›Œë“œ ë¹ˆë„ ê³„ì‚°
    df['week_label'] = df['date'].dt.strftime('%mì›” ') + ((df['date'].dt.day - 1) // 7 + 1).astype(str) + 'ì£¼ì°¨'
    
    # íƒ€ê²Ÿ í‚¤ì›Œë“œ
    target_keywords = ['ë…¸ë˜', 'ì¼€ì´íŒ', 'í•œêµ­', 'ì£¼ë§', 'ë„·í”Œë¦­ìŠ¤', 'ë¬¸í™”', 'ì¸ê¸°', 'ì‘ì›', 'ìµœê³ ', 'ì¼€ë°í—Œ íš¨ê³¼']
    
    # ì£¼ì°¨ë³„ í‚¤ì›Œë“œ ë¹ˆë„ ì§‘ê³„
    keyword_data = []
    
    for week_label in df['week_label'].unique():
        week_df = df[df['week_label'] == week_label]
        all_text = ' '.join(week_df['title'].tolist() + week_df['description'].tolist())
        
        # í…ìŠ¤íŠ¸ ì •ì œ
        cleaned_text = cleanString(all_text)
        
        # í˜•íƒœì†Œ ë¶„ë¦¬
        words = okt.morphs(cleaned_text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        words = [word for word in words if word not in stop_words]
        
        # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
        word_counts = Counter(words)
        
        for keyword in target_keywords:
            keyword_data.append({
                'week': week_label,
                'í‚¤ì›Œë“œ': keyword,
                'ë¹ˆë„': word_counts.get(keyword, 0)
            })
    
    keyword_df = pd.DataFrame(keyword_data)
    
    # Altair ê·¸ë˜í”„
    chart = alt.Chart(keyword_df).mark_line(point=True).encode(
        x=alt.X('week:N', title='ì£¼ì°¨', sort=None),
        y=alt.Y('ë¹ˆë„:Q', title='ë¹ˆë„'),
        color=alt.Color('í‚¤ì›Œë“œ:N', legend=alt.Legend(title='í‚¤ì›Œë“œ')),
        tooltip=['week', 'í‚¤ì›Œë“œ', 'ë¹ˆë„']
    ).properties(
        title='ì£¼ìš” í‚¤ì›Œë“œ ì£¼ì°¨ë³„ ì–¸ê¸‰ ì¶”ì´',
        width=800,
        height=400
    ).interactive()
    
    st.altair_chart(chart, use_container_width=True)
    
    # í•´ì„
    with st.expander('ğŸ“ í‚¤ì›Œë“œ ì¶”ì´ ë¶„ì„ í•´ì„'):
        st.write('''
        **ë¶„ì„ ê²°ê³¼:**
        - **ë…¸ë˜, ì¼€ì´íŒ**: ì‘í’ˆì˜ í•µì‹¬ ìš”ì†Œë¡œ ì§€ì†ì ìœ¼ë¡œ ë†’ì€ ì–¸ê¸‰ëŸ‰
        - **í•œêµ­, ë¬¸í™”**: K-ì»¬ì²˜ ê´€ë ¨ ë‹´ë¡  í˜•ì„±
        - **ì¸ê¸°, ì‘ì›**: íŒ¬ë¤ í™œë™ê³¼ ê´€ë ¨ëœ í‚¤ì›Œë“œ
        ''')
    
    st.divider()

# í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ (Seaborn)
if data_loaded and 'í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„' in analysis_options:
    st.header('ğŸ”¤ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„')
    st.write('> ì „ì²´ ê¸°ê°„ ë™ì•ˆ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ **ìƒìœ„ í‚¤ì›Œë“œ**ë¥¼ ë¶„ì„')
    
    # í˜•íƒœì†Œ ë¶„ì„ê¸° (ê°•ì˜ë¡ 13.ipynb)
    okt = Okt()
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    all_text = ' '.join(df['title'].tolist() + df['description'].tolist())
    
    # í…ìŠ¤íŠ¸ ì •ì œ (ê°•ì˜ë¡ 13.ipynb)
    cleaned_text = cleanString(all_text)
    
    # ëª…ì‚¬ ì¶”ì¶œ (ê°•ì˜ë¡ 13.ipynb)
    nouns = okt.nouns(cleaned_text)
    
    # ë¶ˆìš©ì–´ ì œê±° ë° í•œ ê¸€ì ì œê±° (ê°•ì˜ë¡ 14.ipynb)
    nouns = [word for word in nouns if (len(word) > 1) and (word not in stop_words)]
    
    # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚° (ê°•ì˜ë¡ 13.ipynb)
    word_counts = Counter(nouns)
    top_words = word_counts.most_common(20)
    
    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    word_df = pd.DataFrame(top_words, columns=['ë‹¨ì–´', 'ë¹ˆë„'])
    
    # Seaborn ê·¸ë˜í”„ (ê°•ì˜ë¡ 12.ipynb - st.pyplot)
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # ìƒ‰ìƒ ì„¤ì •
    if chart_theme == 'ë‹¤í¬':
        plt.style.use('dark_background')
        palette = 'rocket'
    elif chart_theme == 'ì»¬ëŸ¬í’€':
        palette = 'Set2'
    else:
        palette = 'viridis'
    
    sns.barplot(data=word_df, x='ë¹ˆë„', y='ë‹¨ì–´', palette=palette, ax=ax)
    ax.set_title('ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ ë¹ˆë„', fontsize=14)
    ax.set_xlabel('ë¹ˆë„')
    ax.set_ylabel('í‚¤ì›Œë“œ')
    
    # pyplot ì¶œë ¥
    st.pyplot(fig)
    
    # í•´ì„
    with st.expander('ğŸ“ í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„ í•´ì„'):
        top3 = [w[0] for w in top_words[:3]]
        st.write(f'''
        **ë¶„ì„ ê²°ê³¼:**
        - ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ: **{', '.join(top3)}**
        ''')
    
    st.divider()

# ì›Œë“œí´ë¼ìš°ë“œ
if data_loaded and 'ì›Œë“œí´ë¼ìš°ë“œ' in analysis_options:
    st.header('â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ')
    st.write('> í‚¤ì›Œë“œ ë¹ˆë„ë¥¼ í‘œí˜„. ê¸€ìê°€ í´ìˆ˜ë¡ ìì£¼ ë“±ì¥í•œ í‚¤ì›Œë“œ.')
    
    # í˜•íƒœì†Œ ë¶„ì„ê¸°
    okt = Okt()
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    all_text = ' '.join(df['title'].tolist() + df['description'].tolist())
    
    # í…ìŠ¤íŠ¸ ì •ì œ
    cleaned_text = cleanString(all_text)
    
    # ëª…ì‚¬ ì¶”ì¶œ
    nouns = okt.nouns(cleaned_text)
    
    # ë¶ˆìš©ì–´ ì œê±°
    nouns = [word for word in nouns if (len(word) > 1) and (word not in stop_words)]
    
    # ì›Œë“œí´ë¼ìš°ë“œìš© í…ìŠ¤íŠ¸
    text_for_wc = ' '.join(nouns)
    
    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    # ë°°ê²½ìƒ‰ ì„¤ì •
    if chart_theme == 'ë‹¤í¬':
        bg_color = 'black'
    else:
        bg_color = 'white'
    
    # ì»¬ëŸ¬ë§µ ì„¤ì •
    if chart_theme == 'ì»¬ëŸ¬í’€':
        cmap = 'Set3'
    else:
        cmap = 'viridis'
    
    # Pretendard í°íŠ¸ ê²½ë¡œ ì‚¬ìš©
    # WordCloud ê°ì²´ ìƒì„±
    wc = WordCloud(
        font_path='font/Pretendard-Regular.ttf',
        max_words=top_n_words,  # ìµœëŒ€ ë‹¨ì–´ ìˆ˜
        width=800,
        height=400,
        background_color=bg_color,
        colormap=cmap,
        random_state=42
    ).generate(text_for_wc)
    
    # ì›Œë“œí´ë¼ìš°ë“œ ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wc, interpolation='bilinear')
    ax.axis('off')
    ax.set_title('ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ í‚¤ì›Œë“œ ì›Œë“œí´ë¼ìš°ë“œ', fontsize=16, pad=20)
    
    # pyplot ì¶œë ¥
    st.pyplot(fig)
    
    # í•´ì„
    with st.expander('ğŸ“ ì›Œë“œí´ë¼ìš°ë“œ í•´ì„'):
        st.write('''
        **ë¶„ì„ ê²°ê³¼:**
        - ì¤‘ì•™ì— í¬ê²Œ í‘œì‹œëœ ë‹¨ì–´ë“¤ì´ í•µì‹¬ í‚¤ì›Œë“œ
        ''')
    
    st.divider()

# ë„¤íŠ¸ì›Œí¬ ë¶„ì„
if data_loaded and 'ë„¤íŠ¸ì›Œí¬ ë¶„ì„' in analysis_options:
    st.header('ğŸ•¸ï¸ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬ ë¶„ì„')
    st.write('> í‚¤ì›Œë“œ ê°„ì˜ **ì—°ê´€ì„±**ì„ ë„¤íŠ¸ì›Œí¬ë¡œ ì‹œê°í™”. í•¨ê»˜ ìì£¼ ë“±ì¥í•˜ëŠ” í‚¤ì›Œë“œë“¤ì´ ì—°ê²°')
    
    # í˜•íƒœì†Œ ë¶„ì„ê¸°
    okt = Okt()
    
    # ê° ê¸°ì‚¬ë³„ ëª…ì‚¬ ì¶”ì¶œ
    all_nouns = []
    descriptions = df['description'].tolist()
    
    for text in descriptions:
        # ì •ì œ
        text_cleaned = re.sub(r'[^ê°€-í£\s]', '', str(text))
        # ëª…ì‚¬ ì¶”ì¶œ
        nouns = okt.nouns(text_cleaned)
        # ë¶ˆìš©ì–´ ì œê±°
        nouns = [word for word in set(nouns) if (len(word) > 1) and (word not in stop_words)]
        all_nouns.append(nouns)
    
    # ì—£ì§€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    edge_list = []
    for nouns in all_nouns:
        if len(nouns) >= 2:
            # ì¡°í•© ìƒì„±
            pairs = list(combinations(nouns, 2))
            edge_list.extend(pairs)
    
    # ì—£ì§€ ë¹ˆë„ ê³„ì‚°
    edge_counts = Counter(edge_list)
    
    # ìµœì†Œ ì—°ê²° ê°•ë„ ì´ìƒì¸ ì—£ì§€ë§Œ ì„ íƒ
    filtered_edges = [(u, v, w) for (u, v), w in edge_counts.items() if w >= network_min_weight]
    
    if len(filtered_edges) > 0:
        # ê·¸ë˜í”„ ê°ì²´ ìƒì„±
        G = nx.Graph()
        
        # ì—£ì§€ ì¶”ê°€
        for u, v, w in filtered_edges:
            G.add_edge(u, v, weight=w)
        
        # ë…¸ë“œê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒìœ„ ë…¸ë“œë§Œ ì„ íƒ
        if len(G.nodes()) > 50:
            degree_dict = dict(G.degree())
            top_nodes = sorted(degree_dict, key=degree_dict.get, reverse=True)[:50]
            G = G.subgraph(top_nodes).copy()
        
        # ë„¤íŠ¸ì›Œí¬ ì‹œê°í™”
        fig, ax = plt.subplots(figsize=(15, 15))
        
        # ë ˆì´ì•„ì›ƒ ìƒì„±
        pos = nx.spring_layout(G, k=2, iterations=50, seed=42)
        
        # ë…¸ë“œ í¬ê¸° ì„¤ì •
        node_sizes = [G.degree(n) * 50 for n in G.nodes()]
        
        # ì—£ì§€ ë‘ê»˜ ì„¤ì •
        edge_widths = [G[u][v]['weight'] * 0.3 for u, v in G.edges()]
        
        # ë…¸ë“œ ìƒ‰ìƒ
        if chart_theme == 'ì»¬ëŸ¬í’€':
            node_color = 'lightcoral'
        else:
            node_color = 'skyblue'
        
        # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        nx.draw_networkx(
            G,
            pos,
            with_labels=True,
            node_size=node_sizes,
            width=edge_widths,
            font_family='Pretendard',
            font_size=12,
            node_color=node_color,
            edge_color='gray',
            alpha=0.8,
            ax=ax
        )
        
        ax.set_title('ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ í‚¤ì›Œë“œ ë„¤íŠ¸ì›Œí¬', fontsize=20)
        ax.axis('off')
        
        # pyplot ì¶œë ¥
        st.pyplot(fig)
        
        # ì¤‘ì‹¬ì„± ë¶„ì„
        st.subheader('ğŸ“Š ì¤‘ì‹¬ì„± ë¶„ì„')
        
        # ì»¬ëŸ¼ ë ˆì´ì•„ì›ƒ
        col1, col2 = st.columns(2)
        
        with col1:
            st.write('**ì—°ê²° ì¤‘ì‹¬ì„±**')
            st.caption('ë§ì€ í‚¤ì›Œë“œì™€ ì—°ê²°ëœ í•µì‹¬ í‚¤ì›Œë“œ')
            
            # ì—°ê²° ì¤‘ì‹¬ì„±
            degree_centrality = nx.degree_centrality(G)
            top_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
            
            degree_df = pd.DataFrame(top_degree, columns=['í‚¤ì›Œë“œ', 'ì¤‘ì‹¬ì„±'])
            st.dataframe(degree_df, use_container_width=True, hide_index=True)
        
        with col2:
            st.write('**ë§¤ê°œ ì¤‘ì‹¬ì„±**')
            st.caption('ë‹¤ë¥¸ í‚¤ì›Œë“œë“¤ì„ ì—°ê²°')
            
            # ë§¤ê°œ ì¤‘ì‹¬ì„±
            betweenness_centrality = nx.betweenness_centrality(G)
            top_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]
            
            between_df = pd.DataFrame(top_betweenness, columns=['í‚¤ì›Œë“œ', 'ì¤‘ì‹¬ì„±'])
            st.dataframe(between_df, use_container_width=True, hide_index=True)
        
        # í•´ì„
        with st.expander('ğŸ“ ë„¤íŠ¸ì›Œí¬ ë¶„ì„ í•´ì„'):
            st.write('''
            **ë¶„ì„ ê²°ê³¼:**
            - **ì—°ê²° ì¤‘ì‹¬ì„±**ì´ ë†’ì€ í‚¤ì›Œë“œëŠ” ê°€ì¥ ë§ì€ ë‹¤ë¥¸ í‚¤ì›Œë“œì™€ í•¨ê»˜ ì–¸ê¸‰ë¨ì„ ì˜ë¯¸
            - **ë§¤ê°œ ì¤‘ì‹¬ì„±**ì´ ë†’ì€ í‚¤ì›Œë“œëŠ” ì„œë¡œ ë‹¤ë¥¸ ì£¼ì œë“¤ì„ ì—°ê²°í•¨ì„ ì˜ë¯¸
            ''')
    else:
        # ì—ëŸ¬ ë©”ì‹œì§€
        st.error('âš ï¸ ì—°ê²° ê°•ë„ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì—£ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ìµœì†Œ ì—°ê²° ê°•ë„ë¥¼ ë‚®ì¶°ë³´ì„¸ìš”.')
    
    st.divider()


# ì¢…í•© ê²°ë¡ 
st.header('ğŸ“‹ ì¢…í•© ê²°ë¡ ')

# í™•ì¥ ë ˆì´ì•„ì›ƒ 
with st.expander('ğŸ” íŒ¬ë¤ í˜•ì„± í•µì‹¬ ìš”ì¸ ë¶„ì„ ê²°ê³¼', expanded=True):
    st.markdown('''
    ### ì¼€ì´íŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ í˜•ì„± í•µì‹¬ ìš”ì¸
    
    ë³¸ ë¶„ì„ì„ í†µí•´ ë‹¤ìŒê³¼ ê°™ì€ **íŒ¬ë¤ í˜•ì„±ì˜ í•µì‹¬ ìš”ì¸**ì„ ë„ì¶œí•˜ì˜€ìŠµë‹ˆë‹¤:
    
    #### 1ï¸âƒ£ ì½˜í…ì¸  ìš”ì¸
    - ë…íŠ¹í•œ K-POP + íŒíƒ€ì§€ ì¥ë¥´ ê²°í•©
    - ì•„ì´ëŒ ì¶œì—°ì§„ì˜ ì—°ê¸°ë ¥ê³¼ ìŠ¤íƒ€ì„±
    - ëª°ì…ê° ìˆëŠ” ìŠ¤í† ë¦¬ë¼ì¸
    
    #### 2ï¸âƒ£ ë¯¸ë””ì–´ ë…¸ì¶œ ìš”ì¸
    - ë„·í”Œë¦­ìŠ¤ ê¸€ë¡œë²Œ í”Œë«í¼ì„ í†µí•œ ë™ì‹œ ê³µê°œ
    - SNSë¥¼ í†µí•œ ë°”ì´ëŸ´ í™•ì‚°
    - ì§€ì†ì ì¸ ì–¸ë¡  ë³´ë„
    
    #### 3ï¸âƒ£ ìŒì•… ìš”ì¸
    - OST ë¹Œë³´ë“œ ì°¨íŠ¸ ì§„ì… (Hot 100)
    - ìŒì› ì°¨íŠ¸ ì—­ì£¼í–‰
    - K-POP íŒ¬ë¤ê³¼ì˜ ì‹œë„ˆì§€
    
    #### 4ï¸âƒ£ ê¸€ë¡œë²Œ ìš”ì¸
    - ë‹¤êµ­ì–´ ìë§‰ ì§€ì›
    - ê¸€ë¡œë²Œ ì‹œì²­ ê¸°ë¡ ë‹¬ì„±
    - í•´ì™¸ íŒ¬ë¤ í˜•ì„±
    ''')

st.divider()  # êµ¬ë¶„ì„ 
st.caption('ğŸµ KíŒ ë°ëª¬ í—Œí„°ìŠ¤ íŒ¬ë¤ ë¶„ì„ ëŒ€ì‹œë³´ë“œ | C221088 ìµœìœ ë¹ˆ | 2025 ë°ì´í„°ì‹œê°í™”')
